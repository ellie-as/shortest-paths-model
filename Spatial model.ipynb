{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd5d68a-4289-41f7-838e-495ecf0d995d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Spatial model\n",
    "\n",
    "Consolidation can be thought of as training a neocortical generative / predictive model on replayed hippocampal memories. For sequential data, the generative model could correspond to an autoregressive sequence model like GPT-2 that learns to predict the next item in the sequence (by minimising the prediction error on sequences from the training data). An environment can be represented as a grid in which each location (i.e. square) is labelled by a random noun. Routes in the environment can then be represented as sequences of form 'apple EAST pancake NORTH material EAST chair', which makes it straightforward to train GPT-2.\n",
    "\n",
    "More specifically, we can represent the shortest path between two locations as 'FROM: apple, TO: chair, PATH: apple EAST pancake NORTH material EAST chair'. This enables us to test the ability to infer the shortest path based on a few examples of a new environment.\n",
    "\n",
    "This notebook simulates the task as follows:\n",
    "* Pre-train model so that it learns how to find the shortest path between two locations in general\n",
    "* Train on a few paths from a new environment, representing the consolidation of spatial sequences encoded in the hippocampus\n",
    "* Compare performance before / after consolidation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac1a12d-ed03-4a17-960d-0a6863681170",
   "metadata": {},
   "source": [
    "#### Installation / imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05917c15-2dc4-4d88-9ab0-5135187faaa3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/huggingface/transformers --upgrade\n",
    "! pip install accelerate evaluate wonderwords simpletransformers --upgrade\n",
    "! pip install huggingface_hub --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7afc1-f112-4b77-800e-b2f47f67e159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "from wonderwords import RandomWord\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import permutations\n",
    "import logging\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import math\n",
    "\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4665fe90-37ff-4348-bfaf-013639b2a630",
   "metadata": {},
   "source": [
    "Define a class for loading a model from a directory, and generating outputs given some input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b9224-5962-4ff5-a898-183de393d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT:\n",
    "\n",
    "    def __init__(self, base_model):\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(base_model)\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(base_model)\n",
    "\n",
    "    def continue_input(self, input_sequence, max_length=200, num_return_sequences=1, no_repeat_ngram_size=0,\n",
    "                       do_sample=False, temperature=0.7, num_beams=1):\n",
    "        \n",
    "        input_ids = self.tokenizer.encode(input_sequence, return_tensors='pt')\n",
    "\n",
    "        # Generate text\n",
    "        output = self.model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            num_beams=num_beams,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            do_sample=do_sample,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "        # Decode the output\n",
    "        sequence = output[0].tolist()\n",
    "        text = self.tokenizer.decode(sequence)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6464ff8e-5309-483a-bd83-0a28dfbba60d",
   "metadata": {},
   "source": [
    "#### Pre-train model on arbitrary stimuli to learn rules of task\n",
    "\n",
    "The get_random_stimuli() function generates a random set of nouns and adjectives (3 for each by default). The stimuli are all possible combinations, e.g. for the adjectives ABC and nouns DEF, the stimuli are AD, AE, AF, BD, etc. The get_stimuli() function is the equivalent but for Oliver's task stimuli. \n",
    "\n",
    "The get_reward() function predicts reward points for a sequence of stimuli. Given a list of stimuli in random order, the stimulus at which the sequence starts, the adjective at which the sequence ends, and the noun that gives 2 points of reward, the function returns a list of stimuli and their rewards, e.g. ['small chair (2)', 'angry chair (2)', 'metal spoon (-1)']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c59468b-afd4-4534-830e-b40f022adcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = RandomWord()\n",
    "nouns = [r.word(include_parts_of_speech=[\"nouns\"]).replace(\" \", \"_\") for _ in range(9)]\n",
    "\n",
    "def create_unique_random_grid(nouns, size=3):\n",
    "    \"\"\"Creates a size x size grid with unique random nouns.\"\"\"\n",
    "    random_nouns = random.sample(nouns, size * size)\n",
    "    return [random_nouns[i * size:(i + 1) * size] for i in range(size)]\n",
    "\n",
    "def find_shortest_paths(grid, start_name, end_name):\n",
    "    \"\"\"Finds all shortest paths from start_name to end_name in a grid. \"\"\"\n",
    "    # Find coordinates of start and end points\n",
    "    start = end = None\n",
    "    for i, row in enumerate(grid):\n",
    "        for j, name in enumerate(row):\n",
    "            if name == start_name:\n",
    "                start = (i, j)\n",
    "            if name == end_name:\n",
    "                end = (i, j)\n",
    "    \n",
    "    # Check if start or end points were not found\n",
    "    if start is None or end is None:\n",
    "        print (\"start or end not found\")\n",
    "        return []\n",
    "\n",
    "    paths = []\n",
    "    start_x, start_y = start\n",
    "    end_x, end_y = end\n",
    "\n",
    "    # Total horizontal and vertical distances\n",
    "    x_dist = end_x - start_x\n",
    "    y_dist = end_y - start_y\n",
    "\n",
    "    # Generate a list of directions taken in the shortest path\n",
    "    # We know that the shortest route is x_dist EAST or WESTs, and y_dist NORTH or SOUTHs\n",
    "    hor_moves = ['EAST' if x_dist > 0 else 'WEST'] * abs(x_dist)\n",
    "    ver_moves = ['SOUTH' if y_dist > 0 else 'NORTH'] * abs(y_dist)\n",
    "    all_moves = hor_moves + ver_moves\n",
    "\n",
    "    # We have a list, e.g. [NORTH, NORTH, EAST, EAST] and we want to find all possible orderings\n",
    "    # Each ordering (i.e. permutation) is a possible shortest path from start_name to end_name\n",
    "    for path in set(permutations(all_moves, len(all_moves))):\n",
    "        sequence = [f'FROM: {start_name}, TO: {end_name}, PATH: {start_name}']\n",
    "        x, y = start\n",
    "        for direction in path:\n",
    "            if direction == 'EAST' and x < 2:\n",
    "                x += 1\n",
    "            elif direction == 'WEST' and x > 0:\n",
    "                x -= 1\n",
    "            elif direction == 'SOUTH' and y < 2:\n",
    "                y += 1\n",
    "            elif direction == 'NORTH' and y > 0:\n",
    "                y -= 1\n",
    "            else:\n",
    "                # Invalid move, skip this path\n",
    "                break\n",
    "            sequence.append(f\"{direction} {grid[x][y]}\")\n",
    "\n",
    "            # add the path when it successfully reaches the end point\n",
    "            if (x, y) == end:\n",
    "                paths.append(' '.join(sequence))\n",
    "\n",
    "    return paths\n",
    "  \n",
    "# example usage\n",
    "grid = create_unique_random_grid(nouns)\n",
    "paths = find_shortest_paths(grid, grid[0][0], grid[2][2])\n",
    "\n",
    "# print the grid and the paths to see the output\n",
    "print(\"Grid:\", grid)\n",
    "print(\"Shortest Paths:\", paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba90dc38-13d5-4915-b7ab-66550bf55c80",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shuffle_stimuli(stimuli):\n",
    "    random.shuffle(stimuli)\n",
    "    return stimuli\n",
    "\n",
    "def get_all_paths_for_grid(grid):\n",
    "    all_paths = []\n",
    "    items = [item for sublist in grid for item in sublist]\n",
    "    for start in items:\n",
    "        for end in items:\n",
    "            if start != end:\n",
    "                all_paths.extend(find_shortest_paths(grid, start, end))\n",
    "    return shuffle_stimuli(all_paths)\n",
    "\n",
    "grid = create_unique_random_grid(nouns)\n",
    "len(get_all_paths_for_grid(grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83366812-1e46-4304-a690-d3cadf2cf35e",
   "metadata": {},
   "source": [
    "We now generate training and test data for the pre-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b93d3f-dd38-40bf-a3e5-cfce37e89d6c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_strs = []\n",
    "for i in range(2000):\n",
    "    nouns = [r.word(include_parts_of_speech=[\"nouns\"]).replace(\" \", \"_\") for _ in range(9)]\n",
    "    grid = create_unique_random_grid(nouns)\n",
    "    training_strs.extend(get_all_paths_for_grid(grid))\n",
    "\n",
    "testing_strs = []\n",
    "for i in range(10):\n",
    "    nouns = [r.word(include_parts_of_speech=[\"nouns\"]).replace(\" \", \"_\") for _ in range(9)]\n",
    "    grid = create_unique_random_grid(nouns)\n",
    "    testing_strs.extend(get_all_paths_for_grid(grid))\n",
    "\n",
    "print(f\"{len(training_strs)} shortest paths on arbitrary grids generated for pre-training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6a49df-cb78-4b49-aa1e-6f894f48ca63",
   "metadata": {},
   "source": [
    "The function below runs a script to fine-tune a gpt-2 model on the arbitrary stimuli.\n",
    "\n",
    "The name_or_path argument is which model to fine-tune from. In the pre-training stage, this will be set to 'gpt2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2433c5-aa7c-496c-a5b7-849674956a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_script(name_or_path='spatial_model', \n",
    "                       num_epochs=3,\n",
    "                       output_dir='./clm_script',\n",
    "                       save_steps=100,\n",
    "                       lr=5e-05 ):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    ! python ./run_clm.py \\\n",
    "        --model_name_or_path {name_or_path} \\\n",
    "        --train_file {os.path.join(output_dir, 'train.txt')} \\\n",
    "        --validation_file {os.path.join(output_dir, 'train.txt')} \\\n",
    "        --per_device_train_batch_size 1 \\\n",
    "        --per_device_eval_batch_size 1 \\\n",
    "        --do_train \\\n",
    "        --do_eval \\\n",
    "        --output_dir {output_dir} \\\n",
    "        --overwrite_output_dir \\\n",
    "        --num_train_epochs {num_epochs} \\\n",
    "        --save_strategy 'steps' \\\n",
    "        --save_steps {save_steps} \\\n",
    "        --learning_rate {lr}       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61e5c52-5e6a-4769-983b-23a1117d1c08",
   "metadata": {},
   "source": [
    "Shuffle the data, write it to train.txt and test.txt files, and train gpt2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9039427a-4609-4b49-b39c-ce4cbedccaf9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf spatial_model\n",
    "!mkdir spatial_model\n",
    "\n",
    "text_file = open(\"spatial_model/train.txt\", \"w\")\n",
    "n = text_file.write('\\n'.join(training_strs))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"spatial_model/test.txt\", \"w\")\n",
    "n = text_file.write('\\n'.join(testing_strs))\n",
    "text_file.close()\n",
    "\n",
    "train_model_script(name_or_path='gpt2', output_dir='spatial_model', num_epochs=5, save_steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d33e27-6eb0-45a7-98e1-bb9d6eee3f54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPT(base_model='spatial_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0dbdfa-a65b-4033-bbd0-455d74eff664",
   "metadata": {},
   "source": [
    "Can the model generalise the rules to new stimuli?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99c4b7-f598-45b5-b891-6c808a1836fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = model.continue_input(\"FROM: table, TO: box, PATH: table SOUTH box\\nFROM: box, TO: chair, PATH: box EAST chair\\nFROM: table, TO: chair, PATH:\", \n",
    "                           do_sample=False)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb1926-5a4a-49d8-9a91-cd8a80410df0",
   "metadata": {},
   "source": [
    "#### Simulate the task\n",
    "\n",
    "The simulate_task() function runs one trial training on a subset of shortest paths from a new environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c75e56c-47d1-408b-8eae-244d03808b80",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_task(seed=0, num_new=1000, num_orig=1000, num_epochs=3):\n",
    "    random.seed(seed)\n",
    "    training_strs = []\n",
    "    \n",
    "    grid = create_unique_random_grid(nouns)\n",
    "    print(grid)\n",
    "    training_strs =  get_all_paths_for_grid(grid)\n",
    "\n",
    "    train_set = training_strs[0:120]\n",
    "    test_set = training_strs[120:]\n",
    "    print(test_set)\n",
    "    \n",
    "    # oversampling trick to avoid overfitting to sequence order\n",
    "    train_set = np.random.choice(train_set, num_new).tolist()\n",
    "\n",
    "    output_dir = f'clm_script_{seed}'\n",
    "    ! rm -rf {output_dir}\n",
    "    ! mkdir {output_dir}\n",
    "\n",
    "    text_file = open(os.path.join(output_dir, 'train.txt'), \"w\")\n",
    "    n = text_file.write('\\n'.join(train_set))\n",
    "    text_file.close()\n",
    "\n",
    "    text_file = open(os.path.join(output_dir, 'test.txt'), \"w\")\n",
    "    n = text_file.write('\\n'.join(test_set))\n",
    "    text_file.close()\n",
    "\n",
    "    train_model_script(name_or_path='spatial_model', \n",
    "                       num_epochs=num_epochs, \n",
    "                       output_dir=output_dir,\n",
    "                       save_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5a05a8-3807-4250-8da6-adc287f17474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simulate_task(seed=0, num_new=2000, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4417ea-c5ca-4080-9131-0a13963eb914",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(base_model='clm_script_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4dacc-7766-405c-8f93-f634d62c6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.continue_input(\"FROM:\", \n",
    "                           do_sample=False)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
